{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf114e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27364\\3938023480.py:5: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/S-DoT_NATURE_2023ë…„(2023.01.01~2024.01.01)/S-DoT_NATURE_2023.12.25-12.31.csv', encoding = 'euc-kr')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('data/S-DoT_NATURE_2023ë…„(2023.01.01~2024.01.01)/S-DoT_NATURE_2023.12.25-12.31.csv', encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98dd7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ì¸¡ì •ì‹œê°„                ì§€ì—­           ìì¹˜êµ¬             í–‰ì •ë™  \\\n",
      "0  2023-12-25_12:07:00   roads_and_parks   Jungnang-gu  Myeonmok4-dong   \n",
      "1  2023-12-25_12:07:00  residential_area   Jungnang-gu  Seongnae1-dong   \n",
      "2  2023-12-25_12:07:00       main_street  Eunpyeong-gu    Jingwan-dong   \n",
      "3  2023-12-25_12:07:00  residential_area   Gwangjin-gu   Junggok2-dong   \n",
      "4  2023-12-25_12:07:00   roads_and_parks   Jungnang-gu    Sinnae1-dong   \n",
      "\n",
      "  ì˜¨ë„ ìµœëŒ€(â„ƒ) ì˜¨ë„ í‰ê· (â„ƒ) ì˜¨ë„ ìµœì†Œ(â„ƒ) ìŠµë„ ìµœëŒ€(%) ìŠµë„ í‰ê· (%) ìŠµë„ ìµœì†Œ(%)  ... ì•”ëª¨ë‹ˆì•„ ìµœëŒ€(ppm)  \\\n",
      "0      0.2      0.0     -0.3     72.0     71.0     69.0  ...          NaN   \n",
      "1     -2.4     -2.5     -2.6     95.0     95.0     94.0  ...          NaN   \n",
      "2     -1.8     -2.2     -2.5     76.0     75.0     73.0  ...          NaN   \n",
      "3     -0.3     -0.5     -0.6     69.0     68.0     67.0  ...          NaN   \n",
      "4     -3.5     -3.7     -3.7    100.0    100.0    100.0  ...          NaN   \n",
      "\n",
      "  ì•”ëª¨ë‹ˆì•„ í‰ê· (ppm) ì•”ëª¨ë‹ˆì•„ ìµœì†Œ(ppm) í™©í™”ìˆ˜ì†Œ ìµœëŒ€(ppm) í™©í™”ìˆ˜ì†Œ í‰ê· (ppm) í™©í™”ìˆ˜ì†Œ ìµœì†Œ(ppm) ì˜¤ì¡´ ìµœëŒ€(ppm)  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN        NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN        NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN        NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN        NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN        NaN   \n",
      "\n",
      "  ì˜¤ì¡´ í‰ê· (ppm) ì˜¤ì¡´ ìµœì†Œ(ppm)             ë“±ë¡ì¼ì‹œ  \n",
      "0        NaN        NaN  2023-12-25 0:07  \n",
      "1        NaN        NaN  2023-12-25 0:07  \n",
      "2        NaN        NaN  2023-12-25 0:07  \n",
      "3        NaN        NaN  2023-12-25 0:07  \n",
      "4        NaN        NaN  2023-12-25 0:07  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "# ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "df_env = df[['ì¸¡ì •ì‹œê°„', 'ìì¹˜êµ¬', 'ì˜¨ë„ í‰ê· (â„ƒ)', 'ìŠµë„ í‰ê· (%)']].copy()\n",
    "\n",
    "# 'ì˜¨ë„ í‰ê· (â„ƒ)'ì™€ 'ìŠµë„ í‰ê· (%)'ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ (ì˜¤ë¥˜ ë¬´ì‹œ)\n",
    "# isdigit()ì´ ì•„ë‹Œ pd.to_numericì„ ì‚¬ìš©í•˜ê³  'coerce'ë¥¼ í†µí•´ NaNìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "df_env['ì˜¨ë„ í‰ê· (â„ƒ)'] = pd.to_numeric(df_env['ì˜¨ë„ í‰ê· (â„ƒ)'], errors='coerce')\n",
    "df_env['ìŠµë„ í‰ê· (%)'] = pd.to_numeric(df_env['ìŠµë„ í‰ê· (%)'], errors='coerce')\n",
    "\n",
    "# 'ì¸¡ì •ì‹œê°„'ì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë‚ ì§œ/ì‹œê°„ ì •ë³´ ì¶”ì¶œ\n",
    "df_env['ì¸¡ì •ì‹œê°„'] = pd.to_datetime(df_env['ì¸¡ì •ì‹œê°„'], format='%Y-%m-%d_%H:%M:%S', errors='coerce')\n",
    "df_env['ë‚ ì§œ'] = df_env['ì¸¡ì •ì‹œê°„'].dt.date # ì¼ë³„ ë¶„ì„ì„ ìœ„í•´ ë‚ ì§œë§Œ ì¶”ì¶œ\n",
    "df_env['ì‹œê°„ëŒ€'] = df_env['ì¸¡ì •ì‹œê°„'].dt.hour # ì‹œê°„ëŒ€ë³„ ë¶„ì„ì„ ìœ„í•´ ì‹œê°„ë§Œ ì¶”ì¶œ\n",
    "\n",
    "# ê²°ì¸¡ê°’(NaN)ì´ ìˆëŠ” í–‰ ì œê±° (ì˜¨ë„/ìŠµë„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)\n",
    "df_env.dropna(subset=['ì˜¨ë„ í‰ê· (â„ƒ)', 'ìŠµë„ í‰ê· (%)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8eab442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ì¼ë³„/ìì¹˜êµ¬ë³„ í™˜ê²½ ë°ì´í„° ì§‘ê³„ (ìƒ˜í”Œ) ---\n",
      "           ë‚ ì§œ            ìì¹˜êµ¬  ì¼ë³„_ì˜¨ë„_í‰ê·    ì¼ë³„_ìŠµë„_í‰ê· \n",
      "0  2023-12-25      Dobong-gu -1.885022  79.466595\n",
      "1  2023-12-25  Dongdaemun-gu  0.805948  75.000000\n",
      "2  2023-12-25     Dongjak-gu  0.902345  76.110553\n",
      "3  2023-12-25   Eunpyeong-gu -2.314875  76.525773\n",
      "4  2023-12-25     Gangbuk-gu  0.051276  77.235969\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì‹œ: ì¼ë³„/ìì¹˜êµ¬ë³„ í‰ê·  í™˜ê²½ê°’ ì§‘ê³„\n",
    "df_daily_avg = df_env.groupby(['ë‚ ì§œ', 'ìì¹˜êµ¬']).agg(\n",
    "    ì¼ë³„_ì˜¨ë„_í‰ê· =('ì˜¨ë„ í‰ê· (â„ƒ)', 'mean'),\n",
    "    ì¼ë³„_ìŠµë„_í‰ê· =('ìŠµë„ í‰ê· (%)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(\"--- ì¼ë³„/ìì¹˜êµ¬ë³„ í™˜ê²½ ë°ì´í„° ì§‘ê³„ (ìƒ˜í”Œ) ---\")\n",
    "print(df_daily_avg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bd1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def preprocess_file(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³ , í™˜ê²½ ë³€ìˆ˜ë¥¼ ì •ì œí•˜ì—¬ ì¼ë³„/ìì¹˜êµ¬ë³„ í‰ê· ì„ ì§‘ê³„í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \n",
    "    Args:\n",
    "        file_path: ì²˜ë¦¬í•  CSV íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        ì¼ë³„/ìì¹˜êµ¬ë³„ ì§‘ê³„ëœ í™˜ê²½ ë³€ìˆ˜ DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. íŒŒì¼ ë¡œë“œ (ì¸ì½”ë”© ì—ëŸ¬ ëŒ€ë¹„)\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_path, encoding='euc-kr', low_memory=False)\n",
    "\n",
    "    # 2. í•„ìˆ˜ ì»¬ëŸ¼ ì„ íƒ ë° íƒ€ì… ë³€í™˜\n",
    "    try:\n",
    "        df_env = df[['ì¸¡ì •ì‹œê°„', 'ìì¹˜êµ¬', 'ì˜¨ë„ í‰ê· (â„ƒ)', 'ìŠµë„ í‰ê· (%)']].copy()\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: íŒŒì¼ {os.path.basename(file_path)}ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ({e})\")\n",
    "        return pd.DataFrame() # ë¹ˆ DataFrame ë°˜í™˜\n",
    "\n",
    "    # ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (coerceëŠ” ë³€í™˜ ì‹¤íŒ¨ ì‹œ NaNìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    df_env['ì˜¨ë„ í‰ê· (â„ƒ)'] = pd.to_numeric(df_env['ì˜¨ë„ í‰ê· (â„ƒ)'], errors='coerce')\n",
    "    df_env['ìŠµë„ í‰ê· (%)'] = pd.to_numeric(df_env['ìŠµë„ í‰ê· (%)'], errors='coerce')\n",
    "\n",
    "    # Datetime ë³€í™˜ ë° ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ\n",
    "    df_env['ì¸¡ì •ì‹œê°„'] = pd.to_datetime(df_env['ì¸¡ì •ì‹œê°„'], format='%Y-%m-%d_%H:%M:%S', errors='coerce')\n",
    "    df_env['ë‚ ì§œ'] = df_env['ì¸¡ì •ì‹œê°„'].dt.date \n",
    "\n",
    "    # 3. ê²°ì¸¡ê°’ ì²˜ë¦¬ ë° ì§‘ê³„\n",
    "    df_env.dropna(subset=['ì˜¨ë„ í‰ê· (â„ƒ)', 'ìŠµë„ í‰ê· (%)'], inplace=True)\n",
    "    \n",
    "    # ì¼ë³„/ìì¹˜êµ¬ë³„ í‰ê·  í™˜ê²½ê°’ ì§‘ê³„\n",
    "    df_daily_avg = df_env.groupby(['ë‚ ì§œ', 'ìì¹˜êµ¬']).agg(\n",
    "        ì¼ë³„_ì˜¨ë„_í‰ê· =('ì˜¨ë„ í‰ê· (â„ƒ)', 'mean'),\n",
    "        ì¼ë³„_ìŠµë„_í‰ê· =('ìŠµë„ í‰ê· (%)', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"âœ… File processed: {os.path.basename(file_path)} -> {len(df_daily_avg)} rows aggregated.\")\n",
    "    return df_daily_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0118143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File processed: S-DoT_NATURE_2023.01.01.csv -> 26 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.01.02-01.08.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.01.09-01.15.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.01.16-01.22.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.01.23-01.29.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.01.30-02.05.csv -> 162 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.02.06-02.12.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.02.13-02.19.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.02.20-02.26.csv -> 162 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.02.27-03.05.csv -> 108 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.03.06-03.12.csv -> 135 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.03.13-03.19.csv -> 108 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.03.20-03.26.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.03.27-04.02.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.04.03-04.09.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.04.10-04.16.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.04.17-04.23.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.04.24-04.30.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.05.01-05.07.csv -> 189 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.05.08-05.14.csv -> 187 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.05.15-05.21.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.05.22-05.28.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.05.29-06.04.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.06.05-06.11.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.06.12-06.18.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.06.19-06.25.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.06.26-07.02.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.07.03-07.09.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.07.10-07.16.csv -> 156 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.07.17-07.23.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.07.24-07.30.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.07.31-08.06.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.08.07-08.13.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.08.14-08.20.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.08.21-08.27.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.08.28-09.03.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.09.04-09.10.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.09.11-09.17.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.09.18-09.24.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.09.25-10.01.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.10.02-10.08.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.10.09-10.15.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.10.16-10.22.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.10.23-10.29.csv -> 156 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.10.30-11.05.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.11.06-11.12.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.11.13-11.19.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.11.20-11.26.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.11.27-12.03.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.12.04-12.10.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.12.11-12.17.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.12.18-12.24.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2023.12.25-12.31.csv -> 182 rows aggregated.\n",
      "âœ… File processed: S-DoT_NATURE_2024.01.01-01.07.csv -> 182 rows aggregated.\n",
      "\n",
      "--- âœ… ìµœì¢… í†µí•©ëœ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ---\n",
      "ì´ í–‰ ìˆ˜: 9481\n",
      "           ë‚ ì§œ            ìì¹˜êµ¬  ì¼ë³„_ì˜¨ë„_í‰ê·    ì¼ë³„_ìŠµë„_í‰ê· \n",
      "0  2023-01-01      Dobong-gu  1.593375  50.397516\n",
      "1  2023-01-01  Dongdaemun-gu  2.383110  46.065217\n",
      "2  2023-01-01     Dongjak-gu  1.474161  50.095652\n",
      "3  2023-01-01   Eunpyeong-gu -0.123913  52.641304\n",
      "4  2023-01-01     Gangbuk-gu -1.991063  49.822464\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ 1. íŒŒì¼ì´ ìœ„ì¹˜í•œ í´ë” ê²½ë¡œ ì§€ì •\n",
    "# ì˜ˆì‹œ: ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ê³³ì˜ í•˜ìœ„ í´ë” 'data_files'ë¥¼ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "folder_path = './data/S-DoT_NATURE_2023ë…„(2023.01.01~2024.01.01)' \n",
    "\n",
    "# ğŸš¨ 2. globì„ ì‚¬ìš©í•˜ì—¬ ê²½ë¡œ ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "# pattern = os.path.join(folder_path, '*.csv')\n",
    "all_csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# 3. ì²˜ë¦¬ëœ DataFrameë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "processed_data_list = []\n",
    "\n",
    "# 4. íŒŒì¼ ëª©ë¡ ìˆœí™˜ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©\n",
    "if not all_csv_files:\n",
    "    print(f\"âš ï¸ ê²½ê³ : ê²½ë¡œ ({folder_path})ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    for file_path in all_csv_files:\n",
    "        df_aggregated = preprocess_file(file_path)\n",
    "        if not df_aggregated.empty:\n",
    "            processed_data_list.append(df_aggregated)\n",
    "\n",
    "# 5. ëª¨ë“  ì§‘ê³„ëœ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ìµœì¢… ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í†µí•©\n",
    "if processed_data_list:\n",
    "    final_combined_df = pd.concat(processed_data_list, ignore_index=True)\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ í™•ì¸ (ì¤‘ë³µ ë‚ ì§œ/ìì¹˜êµ¬ ì¡°í•© ì œê±°)\n",
    "    final_combined_df.drop_duplicates(subset=['ë‚ ì§œ', 'ìì¹˜êµ¬'], keep='first', inplace=True)\n",
    "    \n",
    "    print(\"\\n--- âœ… ìµœì¢… í†µí•©ëœ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ---\")\n",
    "    print(f\"ì´ í–‰ ìˆ˜: {len(final_combined_df)}\")\n",
    "    print(final_combined_df.head())\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 6. ë‹¤ìŒ ë‹¨ê³„ ë¶„ì„ì„ ìœ„í•´ íŒŒì¼ ì €ì¥ (ì„ íƒ ì‚¬í•­)\n",
    "    # final_combined_df.to_csv('./final_aggregated_environment_data.csv', index=False)\n",
    "else:\n",
    "    print(\"âŒ ìµœì¢… í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af0379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_df.to_csv('./filtered_data/sdot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2885969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ì„œìš¸ì‹œ 25ê°œ ìì¹˜êµ¬ ì˜ë¬¸ -> í•œê¸€ ë§¤í•‘ ì •ì˜\n",
    "district_map = {\n",
    "    'Gangnam-gu': 'ê°•ë‚¨êµ¬', 'Gangdong-gu': 'ê°•ë™êµ¬', 'Gangbuk-gu': 'ê°•ë¶êµ¬', \n",
    "    'Gangseo-gu': 'ê°•ì„œêµ¬', 'Gwanak-gu': 'ê´€ì•…êµ¬', 'Gwangjin-gu': 'ê´‘ì§„êµ¬', \n",
    "    'Guro-gu': 'êµ¬ë¡œêµ¬', 'Geumcheon-gu': 'ê¸ˆì²œêµ¬', 'Nowon-gu': 'ë…¸ì›êµ¬', \n",
    "    'Dobong-gu': 'ë„ë´‰êµ¬', 'Dongdaemun-gu': 'ë™ëŒ€ë¬¸êµ¬', 'Dongjak-gu': 'ë™ì‘êµ¬', \n",
    "    'Mapo-gu': 'ë§ˆí¬êµ¬', 'Seodaemun-gu': 'ì„œëŒ€ë¬¸êµ¬', 'Seocho-gu': 'ì„œì´ˆêµ¬', \n",
    "    'Seongdong-gu': 'ì„±ë™êµ¬', 'Seongbuk-gu': 'ì„±ë¶êµ¬', 'Songpa-gu': 'ì†¡íŒŒêµ¬', \n",
    "    'Yangcheon-gu': 'ì–‘ì²œêµ¬', 'Yeongdeungpo-gu': 'ì˜ë“±í¬êµ¬', 'Yongsan-gu': 'ìš©ì‚°êµ¬', \n",
    "    'Eunpyeong-gu': 'ì€í‰êµ¬', 'Jongno-gu': 'ì¢…ë¡œêµ¬', 'Jung-gu': 'ì¤‘êµ¬', \n",
    "    'Jungnang-gu': 'ì¤‘ë‘êµ¬'\n",
    "}\n",
    "\n",
    "file_name = \"./filtered_data/sdot.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# 1. 'Seoul_Grand_Park' ì œì™¸\n",
    "df_filtered = df[(df['ìì¹˜êµ¬'] != 'Seoul_Grand_Park') & (df['ìì¹˜êµ¬'] != 'mobile_type')].copy()\n",
    "\n",
    "# 2. ì˜ë¬¸ ìì¹˜êµ¬ ëª…ì„ í•œê¸€ë¡œ ë³€ê²½\n",
    "df_filtered['ìì¹˜êµ¬'] = df_filtered['ìì¹˜êµ¬'].replace(district_map)\n",
    "\n",
    "# ì²˜ë¦¬ëœ íŒŒì¼ ì €ì¥\n",
    "output_file_name = \"./filtered_data/sdot_processed_ko.csv\"\n",
    "df_filtered.to_csv(output_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d3b2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(\"./filtered_data/sdot_processed_ko.csv\")\n",
    "\n",
    "# 'ë‚ ì§œ' ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³ , 'ì¼ë³„_ìŠµë„_í‰ê· 'ì˜ í‰ê· ì„ ê³„ì‚°\n",
    "seoul_avg_humidity = df.groupby('ë‚ ì§œ')[['ì¼ë³„_ìŠµë„_í‰ê· ','ì¼ë³„_ì˜¨ë„_í‰ê· ']].mean().reset_index()\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ë³€ê²½\n",
    "seoul_avg_humidity.columns = ['ë‚ ì§œ', 'ì„œìš¸ì‹œ_í‰ê· _ìŠµë„(%)','ì„œìš¸ì‹œ_í‰ê· _ì˜¨ë„']\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
    "seoul_avg_humidity.to_csv(\"./filtered_data/seoul_daily_avg_humidity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da470558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
